12/28/2015
The folder is generated on 12/28/2015. Here is the email from Hee-Jong,
Jerry,

You got the Dropbox share message, right?
Please take a look at the dropbox and see the two files.

These are two simulations with equal random seeds and we are interested in the difference in BAO feature between these simulations.
Can you calculate the power spectra for these two using your FFT code?
Start with small number of meshes, i.e., 256^3 and then try to increase to 512^3.

These are hdf format. Please find out how to read this kind of files.

I am unclear about the exact order inside the file. I will ask the person who generated the simulations for more details.

Hee-Jong


Code cicps_wnw.py is copied file cicps.py from FFT_PS. It’s used to calculate power spectrum from the galaxy number density distribution using FFT. Below is some information to read hdf5 file:/Users/ding/Documents/playground/WiggleNowiggle/a_note

From: Yu Feng <yfeng1@berkeley.edu>
Date: Mon, Dec 28, 2015 at 5:31 PM
Subject: Re: [Fwd: Re: sims]
To: Hee-Jong Seo <sheejong7@gmail.com>
Cc: Marcel Schmittfull <mschmittfull@lbl.gov>, Shun Saito <shun.saito@ipmu.jp>, Florian Beutler <fbeutler@lbl.gov>


Hi Hee-Jong,

The file is in HDF5 and position velocity are saved as arrays of
3-vectors.

Here is an example python script that reads in the catalogue.

import h5py

f = h5py.File('normal_fof00100_0.6452_0.168.hdf5')

# mass of a particle, watch out if OmegaM != 0.292
m0 = 0.292 * 27.75e10 * (1380 / 2048.) ** 3


groups = f['FOFGroups'][:]

groups[0] represents the void, with a mass of 0
groups[1] has the information of halo 0, and groups[1] has information
of halo 1 ...

You can use each component of the catalogue:

print groups['Position']
print groups['Velocity']
print groups['Length'] * m0

You can unpack the 3-vectors via :

vx, vy, vz = groups['Velocity'].T
x, y, z = groups['Position'].T
mass = groups['Length'] * m0

Then the 1st entry (vx[1] vy[1] vz[1], x[1] y[1] z[1], mass[1]) is the
information of halo 0, and so on (2nd entry is halos 1, etc).

Does this information help?


- Yu


12/29/2015
Deal with the data files normal-cicps_N_256.dat, normal-cicps_N_512.dat, no_wiggle-cicps_N_256.dat
and no_wiggle-cicps_N_512.dat generated from the code cicps_wnw.py, using the code plot_Pk.py.
Put results in folders writeup_1 and writeup_2.

12/31/2015
test_matterpower.dat is generated from CAMB using parameters as 
omega_0 = 0.3175                       # total matter ratio
omega_b = 0.0490                      # baryon ratio
h = 0.6711                           # reduced Hubble constant: H_0/(100 km/s/Mpc)
TCMB = 2.727                          # CMB temperature(K)
corresponding, transfer_fun.dat is the data of transfer function from transfer_fun.py.

Fix a bug in code plot_Pk_rsd.py which mixed up reading data file for P(k) in real space and redshift space. 

BTW, 
readhdf5.py tests how to read hdf5 files.
cicps_wnw.py generate P(k) using fft with cic window function.
cicps_wnw_RSD.py based on cicps_wnw.py, adds redshift distortion on z direction.
plot_Pk.py plots Pk_wiggled/Pk_no_wiggle in real space.
plot_Pk_rsd.py plots Pk_wiggled/Pk_no_wiggle in redshift space.


01/14/2016
Modified the code plot_Pk.py.

01/26/2016
Modify the code plot_Pk.py and powell_fitBAO.py. In the latter, we added the nonlinear damping effect.

02/02/2016
Create the folder baoshift which stores one set of data files generated by Yu Feng. Here is the email from him

Hi Hee-Jong and Zhejie,

A first set of simulations is ran. They can be accessed from
edison at

/scratch1/scratchdirs/yfeng1/baoshift/

The random seed is identical to the previous simulation
(seed=00000100), so the large scale structure shall look more or less
the same.

The wiggle initial condition has 'wig', and no wiggle IC has 'now' in
the directory name.

For testing numerical convergence, I ran two configurations, 10 steps
and 20 steps.

The friend-of-friend groups are in fof_x.xxxx.hdf5 files.

There will also be 1% subsample files of the dark matter particles
(sub_x.xxxx.hdf5), in case we would like to look at the DM in the
future, without dealing with the 300GB-each snapshots.

- Could you take a look if these data are reasonable?

- We also need to see if the 10 step simulation has converged. The z=1
(a=0.5) snapshot is especially worrisome, as it has only 5 steps, and
the mass function could be bad. -- I haven't checked z=1 with 5 steps,
but I knew at z=0, 5 steps gives very poor mass function.
If your analysis shows 10 step differ greatly from 20, we shall do a 40
step run to ensure 20 has converged before moving on running the other
29x2 simulations.


Best,

- Yu 

and an email about the analysis work from Hee-Jong,
Jerry,

1. Could you please calculate real-space P_wiggle(k) (two P(k) on the top of each other in a log-log plot) for 10 steps and 20 steps using  fof_x.xxxx.hdf5 files ?
2. Two P_wiggle/P_nowiggle graphs in log-linear plot for 10 steps and 20 steps.

3. Do the same for sub_x.xxxx.hdf5.

Thanks,
Hee-Jong

02/03/2016
Schedule008
1. Check 1 sigma error of \alpha in the fitting procedure. Use k_mid of the k bin as the k value when 
     we calculate P(k) at k from FFT. (Fix \alpha=1, check the fitting result?)

3. Make the FFT analysis code run faster. 

2. For the weak lensing project, include cross power spectrum C^ij(l), i.e. covariance matrix should include
    cross power spectra too. Check the equation to calculate Cov(C^ij(l), C^pq(l)). Similarly as only including
    auto power spectra, retract P(k) from C^ij(l).
 
02/10/2017

From Yu:
Yes. @Hee-Jong, Do you have a specific mass cut of interest?
Otherwise I would suggest starting with 1e13.

The field 'Length' in the file is the number of particles, and the mass
of a particle is

27.75e10/h Msun * 0.307 (0.307=Omega_M) * (1380/2048.) **3 ~ 

Something around 2.4e10/h Msun I would say.

If the number of halos you select from the 10 steps run is significant
less (>10%) than that from the 20 steps run, I would recommend you just
cut the same number of halos (according to the 20 steps run) from both
simulations and do the analysis. This is 'abundance matching' since
both catalogue have already been sorted by mass.

- Yu

02/13/2016
generate folder run0-00000100-10-wig-fft-Pk, which contains fof and sub power spectra
in real and red shift distortion space.
Similarly for folders run0-00000100—20-now-fft-Pk.

run1-00000100-10-now-fft-Pk and run1-00000100-20-now-fft-Pk store P(k) from run1 simulation data generated by Yu, in his email, he said:

Hi Hee-Jong and Jerry,

Presumably the code will take a (2d) power spectrum on [k, mu] bins as
the input?

Going back to the old thread that 10 and 20 step subsamples mismatched
the large scale, I've rerun the 10 and 20 step nowiggle simulation with
a fix, and produced the subsample files at:

/scratch1/scratchdirs/yfeng1/baoshift

The runs are named after (run1-****)

Could you take a look if the issue is resolved? 

I believe this is the final barrier before farming this out to order of
10~ 30 runs.


- Yu

In Marcel Schmittful email, he mentioned:

In all the four folders, k value of these data files is the midpoint of each k bin. 
 
Right, for this I fitted alpha_BAO with flat prior [0.9,1.1] and 
Sigma_nl with prior [0.1,15.0] Mpc/h.

Regarding error bars, they might be larger in your case if you look at 
halos because of shot noise.

Best,
Marcel

02/16/2016
 Jerry currently has only an isotropic BAO fitting code. We will
> extend it to 2D.
> I asked Jerry to do
>
> 1. plot alpha using real-space P(k) as a function of redshift for 10
> steps and 20 steps
>
> 2. plot alpha using redshift-space P(k) as a function of redshift for
> 10 steps and 20 steps
>
> 3. 4. the same for Signl for the best fit.
>
> Although it is not a 2D BAO scale fit, it should give us fairly good
> information on the BAO feature.

02/17/2016
From Zvonimir Vlah, I made the confirmation that planck_… and planck_…smooth… are the theoretical power spectrum for simulation run0 and run1.
Using code fitbao.py, we can regenerate alpha close to 1.001 and one sigma error of alpha is close to 0.01%~0.02%.

From Zvonimir:
> Hi Jerry,
> so these linear power spectra: 'planck...' and 'planck_... smooth...'
> are valid for Planck-like cosmology.
> With these spectra I've sent the file that contains corresponding
> cosmological parameters.
> I'd guess Yu has used these as initial conditions for running the
> simulations.
> Yu correct me if I'm wrong...
>
> Best,
> Zvonimir

From Marcel:
Right, just to summarize/clarify: 'planck...' spectra are for Planck 
cosmology but normal.dat and smooth.dat are for some old WMAP cosmology. 
Sims used Planck cosmology (Yu, let us know if not). So it makes sense 
that you get a bias if you use WMAP power spectra to fit Planck sims.

Best,
Marcel

02/19/2016
Hi,

I have submitted the N_s=40 run with seed 100; it shall finish over the
weekend.

Glad that more N_s = 10 runs are not that urgent. 

There seems to be an issue with Edison's IO system, and all of my 9 x
N_s=10 runs stalled at writing out the snapshots. :-(

Yu
On Fri, 2016-02-19 at 14:41 -0500, Hee-Jong Seo wrote:
> Marcel,
> 
> Even though we expect that the actual errors would be greater than
> what is assumed here, it appears that the difference between 10 steps
> and 20 steps are much larger than the statistical errors we aim at.
> The alpha shift values are not monotonic with redshift in the case of
> 10 steps.
> 
> I think that it may be worth testing at least one 40step simulation
> to compare with the 20step.
> 
> Hee-Jong 
> 
> On Thu, Feb 18, 2016 at 1:00 PM, Marcel Schmittfull <mschmittfull@lbl
> .gov> wrote:
> > I see, thanks. Are the differences between 10 and 20 steps in the
> > top panels of Fig. 1 and 2 acceptable or do we need higher
> > accuracy? (I forget our target for error on alpha). If the chi^2
> > are still very high because of too small error bars or because the
> > model is too simple then I'm not sure how much you can trust the
> > best-fit alpha's. From the last plot it looks like 10 and 20 time
> > steps are very similar right? Then were are probably good to go for
> > more realizations? Or would you prefer something like 20 and 40
> > time steps instead of 10 and 20?
> > 
> > Best,
> > Marcel

02/22/2016
Yu generated run2 simulation data with 40 steps. I calculated P(k) of these data


02/26/2016
Emails from 02/23-25 about number of steps for N-body simulation

02/23/2016
Yu:
Hi Jerry and all,

Thanks for the figures. My comments:

0. For these ratio plots, what matters the most is whether the cross-correlation coefficient between fastPM runs and TreePM have converged.

1. We knew that the cross-correlation coefficient of halos converge as early as 10 'effective' steps. It is therefore not surprising that in Figure 1, all redshifts Ns=20 and Ns=40 are very similar -- the Ns=20 run has 10 effective steps before a=0.5 -- sufficient to converge the cross-correlation coefficient.

2. We also knew that the  CCC of matter doesn't converge until 40 'effective' steps. In Figure 2 at a=0.5/0.625, there is disagreement because the effective number of steps is 10 for Ns=20 and 20 for Ns=40. 

3. For halos, there is additional stochasticity due to noise of finding halos (even though the initial modes are exactly the same). This may have contributed to the disagreement in Figure 1, and Figure 3. Using more realizations shall be able to get rid of these with sqrt(N) rule. We can estimate the number of required simulations by looking at the variance in Figure three divided by the desired error.


Yu

02/24
Hee-Jong:
Thanks for the reply, Yu.
BTW, Jerry will be out of the email contact for the next two days.


0. For these ratio plots, what matters the most is whether the cross-correlation coefficient between fastPM runs and TreePM have converged.
So, what we are concerned with Figure 3 is the scatter around the CCC, I presume?  From your comment #4, this scatter will also decrease with the increasing number of simulations just like nominal sample variance effect?

1. We knew that the cross-correlation coefficient of halos converge as early as 10 'effective' steps. It is therefore not surprising that in Figure 1, all redshifts Ns=20 and Ns=40 are very similar -- the Ns=20 run has 10 effective steps before a=0.5 -- sufficient to converge the cross-correlation coefficient. 
This is for halo samples?
 
 
2. We also knew that the  CCC of matter doesn't converge until 40 'effective' steps. In Figure 2 at a=0.5/0.625, there is disagreement because the effective number of steps is 10 for Ns=20 and 20 for Ns=40. 
So, do we want Ns=80 to study the alpha difference between matter vs halos?


3. For halos, there is additional stochasticity due to noise of finding halos (even though the initial modes are exactly the same). This may have contributed to the disagreement in Figure 1, and Figure 3. Using more realizations shall be able to get rid of these with sqrt(N) rule. We can estimate the number of required simulations by looking at the variance in Figure three divided by the desired error.
 
 
So it seems that everything is as you expected. That is a good news!

I think that the scatter is still much smaller than the typical sample variance that we can move on.
If I understood you correctly, if we want to have a reliable alpha from subsampled dark matter, we need Ns=80, while Ns=40 is good for the halos?
If so, we could either run many Ns=80 runs as a default,
or run many Ns=40 runs as a default and run a couple of Ns=80 runs just to derive alpha difference between the halos and dark matter?

What do you think?

Hee-Jong


Hee-Jong:
Yu,


This is a reasonable assumption, but I have never tested it myself. We
need to verify this by running more simulations with different seed.
Sounds like an interesting test. 

> >
> > 1. We knew that the cross-correlation coefficient of halos converge
> > as early as 10 'effective' steps. It is therefore not surprising
> > that in Figure 1, all redshifts Ns=20 and Ns=40 are very similar --
> > the Ns=20 run has 10 effective steps before a=0.5 -- sufficient to
> > converge the cross-correlation coefficient. 
> >
> This is for halo samples?

For halo samples with M>1e12/h. You can refer to the draft fastPM paper
that we will submit soon. https://www.overleaf.com/read/dqcqvtrmsxkc Fi
gure 4 shows the convergence of matter CCC.
Thanks! I will take a look.  

Even with 10 steps, the CCC of matter at k=0.5 is > 99.5%; that's
suggesting, there is nothing to gain with Ns>20. I noticed Jerry
usually plot up to k=1. Do you need k > 0.5?

I don't think so.

What about we do 4 Ns=80 runs as a starter?

Sounds good to me. 

Thanks!
Hee-Jong 
 
Yu

02/24
> > > On Wed, 2016-02-24 at 19:32 -0500, Hee-Jong Seo wrote:
> > > I think that Jerry followed Marcel's paper. Was it kmax=0.3? 
> > > If we have this small sample variance, I won't mind going to
> > > kmax=0.5
> > > after reconstruction.
> > Thanks. I got a reply from Jerry too. It is kmax=0.3. The CCC is
> > shall
> > be sub 0.1% even with 10 effective steps at k=0.3. Both Ns=20 and
> > Ns=40
> > satisfy this.
> > 
> > Thus I don't think we understand the reason why DM subsample
> > measurement hasn't converged yet. It must be more than CCC?
> Did the subsampling use the same random seed? I.e., the same particle
> IDs after subsampling?

No. I changed the seed in the run with 40!

Yu

02/25
Yu:

Hi, 

Just fiddled with the numbers. It is slightly getting more expensive
when we go to 80. (~ 3K mpp units each)

I will submit 3x40 simulations when I get around to babysit them,
likely later of the day.

Marcel:
Hi,

Sorry for missing parts of the discussion. I just quickly wanted to 
confirm that for DM subsamples it's important to choose the same 
particle IDs in wiggle and nowiggle simulations to make sure that cosmic 
variance is cancelled (e.g. you could select ID % 101 == 0).

Best,
Marcel


03/05/2016
Folder run2 is copied from the same name folder in NERSC /scratch1/scratchdirs/jerryou/baoshift/run2 
which contains P(k) from simulation data using different value of seeds(000-009).

03/08/2016
Folder run2_Cov_P-40-now and run2_Cov_P-40-wig contain covariance matrix of P(k) using the formula below
C_ij = 1/(N_s-1) <(Pi-Pi_avg)(Pj-Pj_avg)>

Folder run2_Pmean_40_now and run2_Pmean_40_wig contain the mean P(k) for each k bin.

Folder run2_sigma_Pkmean contains 1 sigma error of Pk from run2 simulation data, as well as 1 sigma error
of P_wig/P_now using the formula below:
sigma^2_Pk = 1/P1^2*(P2/P1)^2 s1^2 + 1/P1^2 s2^2, where P1 means P_now, P2 means P_wig, s1 is 1 sigma 
error of P1 and s2 is 1 sigma error of P2.
But there is a question that the formula above is based on the independence between P1 and P2. Otherwise,
it’s not correct. We should calculate the 1 sigma error of P_wig/P_now from 
C_ij = 1/(N_s-1) <(Pi-Pi_avg)(Pj-Pj_avg)>, where Pi and Pj corresponding to P_wig/P_now at ith and jth k
bin, respectively.

As a result, there is bias of sigma_{P_wig/P_now} from two methods. I think P1 and P2 are not independent.
Choose the result from the second method.
(have moved these folders to the folder baoshift_run2 and code Cov_Pk.py to code_script)

Something haven’t done today is
It could be interesting to look at the variance of the alpha parameter
from fitting, and see if the error of that is low. —-From Yu, 03/08/2016 
 
 
03/10/2016
Made the code fitbao_run2.py to get sigma error of alpha.

03/23/2016
Update what I have done from 03/10
run2_2D_Pk stores 2D P(k) from nbodykit package, and analysis of relevant variables. 

04/07/2016
Have organized data files and code scripts in this directory.
Move all the code using Powell fitting method for 1D P(k) into the folder run2_1D_power

04/25/2016
Record something from Hee-Jong and Yu useful:

> > > Guys,
> > > 
> > > Do you have a recommendation for the number of mu bins for a
> > > reliable alpha_parallel fitting?
> > > I used to do 100 equally spaced mu bins long ago.
> > > Florian, when you derived multipoles from P(k, mu), how many mu
> > > bins did you use?
> > > 
> > > H.

On Mon, 2016-04-25 at 10:01 -0400, Hee-Jong Seo wrote:
> Florian,
> 
> The Nbody kits Jerry is currently using outputs P(k,mu)  (it can
> output multipoles, too, Yu?).
I believe it output multipoles too. 

There is a 'poles' parameter. Something like this would work:

mode: 2d
Nmesh: 256
output: ../output/test_power_fastpm_2d.txt
poles : [0, 2, 4]
field:
    DataSource: 
        plugin: FastPM
        path: ../data/fastpm_1.0000
        rsd: z
    Transfer: [NormalizeDC, RemoveDC, AnisotropicCIC] 


04/26/2016
Generate P(k, \mu) with 100 mu bins for run2 and run3 data. Get the mean P_wig/P_now and it’s covariance matrix
Calculate bias of fof P(k) with respect to sub P(k).

Before circulating this, let's do a couple of things right.

First, for fof simulation, we want to get bias for each cases. 
Without doing that, these plots don't mean much, since we do not know how to interpret them.

1. Get bias for all cases. I will correct my recommendation before.
1-1. Get the real space monopole power spectrum for fof and sub-dm. 
1-2  remove the shot noise, i.e., 1/nden from both fof and sub-dm.
1-3 The the rough ratio for k<0.1h/Mpc. You can make this an automated process.

2. What is the number of mu bins? I want it to be ~100.

Hee-Jong 

#####
# 05/15/2016
############
Data is in the folder run_2_3_2D_power/2d_Pk_mu_100_masscut.
Last three days, I generated P(k) of run2 and run3 after applying mass cuts (using 5 logmass points.)
Get the mean P(k) at a certain a and logmass point and the covariance matrix.
Use MCMC routine to fit the parameter alpha_para, alpha_prep, Sigma_xy, and Sigma_z.

05/26/2016
Finished the write-up 21 on 05/24/2016. Sent it to others and the feedback is good.
What I need to correct and do further is 

1. Plot the P(k) covariance matrix depending on k only. We can set \mu=0.0, suggested by Marcel.

2. Yu suggested 3 issues:
   2.1 Calculate the stochasticity of the power spectrum from the simulation, http://arxiv.org/abs/1603.00476
   2.2 Use fill command in matplotlib to plot fitted anisotropic power spectrum versus the theoretical one.
   2.3 Use different colors to show the fitted parameter \alpha_perp and \alpha_para of power spectra from run2 and run3 simulations.

3. Use smaller number of \mu bins and do the same process again. Compare the results with that from 100 \mu bin case.

4. Find the reference and show the modified fitting model reasonable, show the deviation as well.

5. Transform the simulation hdf5 files to text files (I thought it later, maybe generating binary data file is quicker and time saving.)


05/27/2016
Tried the item 5, transforming hdf5 data to .dat. The problem of transforming hdf5 to binary files is the lost of precision using Python. How to set
the precision as float64? Have no idea so far.

06/02/2016
Asked Yu about calculating stochasticity in our case, not very sure why we need that neither.

06/03/2016
copy the P(k, \mu) with 5 \mu bins and mass cut from edison. MCMC fitting parameters in the folder 2d_Pk_mu_5_masscut (in run_2_3_2D_power).

06/06/2016
Yu confirmed calculating stochasticity between Wiggle and No-wiggle power spectrum.
Also he showed me the example of batch file calculating cross-power spectrum.
From Yu’s email:

/global/project/projectdirs/m779/sahagunj/halocross/PB00/power13.0-0.168.job

/global/project/projectdirs/m779/sahagunj/halocross/10steps-x2/powermm.job

In addition, we are in the process of updating the nersc 'default'
installation of nbodykit at /usr/common/contrib/bccp. I wonder if Jerry
wants to try it out?


From Hee-Jong:
Hi all,

I had a week-long vacation last week, and before we forget the context of the skype discussion, I would like to summarize it here.

1. Yu will run 60 more sims of 40 steps as well as 20 more sims of 20 steps.
Yu will first fill in z=1.5 and z=2 outputs of the current 20 (wig and nowig) simulations.

2. While Yu generates the z=1.5 and z=2 outputs of the current 20 sims, I will conduct reconstruction on the current simulations. I have a question to ask here.
Do we want to reconstruct the nowiggle density field as well? I guess we do since reconstruction will change the shape as well.

3. We will send the derivation of eq (2), i.e., the fitting formula to account for a deviation of the power spectrum shape from the initial broadband shape.

4. Update Figure 5 and 6. 

5. Check Stochasticity.
 
6. Calculate propagators between the initial field and the final field, and for this, Yu will send me Fourier modes of the initial fields.

Thanks,
Hee-Jong


06/08/2016
Record the email from Yu,
Hi Jerry,

Thanks. 

The basic idea is you no longer need to install nbodykit on NERSC
yourself. (no more 20 minutes of waiting) 

There is an uptodate version (re-built every-day from the 'stable' and
'unstable' branch) on NERSC for you to use if you source the
environment from /usr/common/contrib/bccp. It also takes care of the
optimization for launching large parallel jobs on nersc computers.

I produced a minimal example at

https://github.com/bccp/nbodykit/blob/master/nersc/example.sh

The line to invoke nbodykit is srun-nbkit. Everything else remains the
same as the other example files I sent you.

If this doesn't work, let me know.

Yu

06/10/2016
Made the code get_Pk_0.2.py in the folder run3 to roughly calculate P(k) at k=0.2 for Subsample simulation data.

06/12/2016
Note again: In the folder run_2_3_2D_power, there are code and results corresponding to run2 and run3 simulations.

Made a folder 2d_Pk_mu_100_cross in run_2_3_2D_power, dealing with cross power spectrum from 2 simulations.


06/13/2016
From Hee-Jong’s email
Jerry,

I generated P(k) for two cases of fof, wiggle and without wiggle for run2 and 00000100-40. This is at z=1 and particle cut at 

See
/global/project/projectdirs/desi/users/sheejong

NW0/ for nowiggle and WG0/ for wiggle.

There are many files,  but the file format you want is
DD/kaver.*.dat 
is for real space before reconstruction
DD/kaves.*.dat
is for redshift space before reconstruction
ALL/Rkaver.*.dat is real space P(k) after reconstruction
ALL/Rkaves.*.dat is redshift space P(k) after reconstruction.

There are R* files in DD directories as well, but you can ignore them.

You can take a look at these files and see if the P(k) before reconstruction reasonably matches yours from nbodykit and how the BAO looks after reconstruction. 

I will run the code for other cases as well.  
H.


Actually, please let me know first if the format and the k and mu spacing is good for you before I run the entire thing.

For your reference, I am following
http://adsabs.harvard.edu/abs/2007ApJ...664..675E
to do reconstruction.

H. 

#————————#
Made the folder Reconstruct_power.
In the folder, test_reconstruct.py is used to examine power spectrum data from Hee-Jong’s reconstruction code. It matches
well with the nbodykit power spectrum.


# 06/15/2016
# From Yu’s email:
Relating to stochasticity:
In the unmatched limit has to be careful about what we mean. In our
model, we use

P1 = b1 P + 1 /n
P2 = b2 P + 1 / n
Px = sqrt(b1b2) P + (1 -f) / n


We are only defining stochasticity on the shot noise part -- sort of by
volume -- thus the limit -> 1 is true in k->inf but not k->0 if you
take Px = 0 -- in reality this doesn't happen though (we always have Px
close to P1 and P2).

06/29/2016
From Hee-Jong’s email on 06/28

No, I will take it back.
Eq (25) of Seo et al 2016 should be the fitting formula, and the nowiggle and wiggle ration should have the same factor, (1+beta(1-S(k))\mu^2)^2, i.e., it should be cancelled.
Yes, please check the average P(k) in real space vs redshift space, and pre vs post reconstruction to make sure that things look reasonable.
Post reconstruction, you should be able to see that the amplitude is fitted by (1+beta(1-S(k))\mu^2)^2 rather than (1+beta\mu^2)^2 in redshift space.

Another small detail is to put beta(1-a*S(k)) in the fitting formula to replace beta. So, a= 0 before reconstruction and a=1 post reconstruction.
'a' as well as S(k) are not fitting parameters, but depends on a form I used for reconstruction. 

S(k) = exp(-0.25*k**2*Sigsm**2)

where Sigsm I used is following.

At z=1, 
mcut  Sigsm**2 
34      2*31
103    2*38
290    2*49
681    2*65
1390  2*86

You can try this first and see if the answers change for the averaged power spectrum at z=1.

Hee-Jong

update the code multiplot_mean_individual.py to plot P(k, \mu)


07/06/2016
Due the shot noise at high bias, the wiggle amplitude of P_wig/P_now from simulations is larger than the theoretical one. This causes the
value of Sigma_xy and Sigma_z go to 0 in the fitting.
Start do mcmc fitting for the reconstructed run2 and run3 simulations.


07/13/2016
From Hee-Jong’s email:
Yes, it is hard to see what i want based on this plots.
It may be better to see standard deviation plot among 20 sets.

Assuming that the difference is not large, if we use the observable as
"(Pobsw-Pobsnw)/(b^2G^2Plinnw)",
I think that we can avoid this ambiguity about A term. I.e., we can
fit without the A term.
Do you want to try this (only for one redshift in real space)? Or do
you want to circulate the current results first?

If you want to circulate the current results,
I think that we want to send out (focusing on the real space. say that
you have the redshift space case and we want to make sure that the
real space makes sense first.)
1. P(k) before reconstruction in real and redshift space. Not P/Psm.
2. P(k) after reconstruction in real and redshift space.
3. The best fit alpha values and the best fit Sigma values plot in
real space for
   3.1 for no shot-noise subtracted case without the A term (however,
you subtract shot noise from DM anyway, right?)
   3.2 shot-noise subtracted case with A term free (I believe that
this gives almost the same result as the no-shot-noise subtracted case
with A term free, right?)

4. Pick one of the high bias cases at one redshift and show (P-P)/P
data points (without the dispersions) and best fit line and the linear
line for 3.1 and 3.2 case. We talked about this yesterday.

Say that 3.1 is assuming all bias effect in power spectrum is
multiplicative, i.e., cancels out exactly by taking a ratio
while 3.2 is assuming all bias effect is additive, i.e., goes not
cancel out exactly by taking a ratio. So, we introduced the A term.
The real answer should be somewhere between the two.

Hee-Jong

Jerry,

On Wed, Jul 13, 2016 at 3:19 PM, Ding, Zhejie <zd585612@ohio.edu> wrote:
> I'm wondering whether we could calculate mode-coupling P_mc from power
> spectrum roughly.
>
With some extra information, we can do it.
For our purpose, it is best to marginalize over by using many free
parameters. But of course, we want to avoid using too many free
parameters.

> As we discussed before, it could mimic the damping effect. And maybe it's
> possible that it replaces
>
> the effect of the damping exponential function. If we could get A roughly,
> in the mcmc fitting, I could
>
> assign it as a prior. I'm not sure it helps, but would like to try.

The problem is that not only A but also bias is scale-dependent, which
is the reason why A did not fix the problem for highly biased case.
Again, it is better to introduce many free parameters if we really
want to do it correctly.
I think that fitting to
(Pobsw-Pobsnw)/(b^2G^2Plinnw)
may work better since we don't need to worry about Pmc here. All
difference including Pmc other than the BAO is subtracted in
(Pobsw-Pobsnw).
This is also the way plotted in Eisenstein et al. 2007 (the paper you
presented), except for using Plin rather than using Plinnw.
I think that we should try (Pobsw-Pobsnw)/(b^2G^2Plinnw) .

>
>
> P(k) in your data file is the observed power spectrum (without shot noise
> subtracted), right?

Yes, without shot noise subtraction for the biased cases. For subdark
matter, please subtract the shot noise.

>
>
> And I prefer to summarize the results we have so far. I would finish this
> before the meeting tomorrow.
Sounds good.

Hee-Jong

